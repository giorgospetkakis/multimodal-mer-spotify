{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import editdistance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents = pd.read_csv(\"data\\MoodyLyrics4Q_featurized.txt\", index_col=0)\n",
    "sentiment = all_sents.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "vecs = []\n",
    "for i in range(len(sentiment)):\n",
    "    # print(re.sub(r\"\\[|\\]|\\n|\\'\", \"\", sentiment[[\"LYRICS_VECTOR\"]].iloc[i][0]))\n",
    "    long_string = re.sub(r\"\\[|\\]|\\n|\\t|\\'\", \"\", sentiment[[\"LYRICS_VECTOR\"]].iloc[i][0]).replace(\"  \", \" \").split(\" \")\n",
    "    e = []\n",
    "    for item in long_string:\n",
    "        if len(item) != 0:\n",
    "            e += [float(item)]\n",
    "    vecs += [e]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_vecs = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vecs = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vecs = np.hstack((title_vecs, lyric_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_boi = np.hstack((sentiment.iloc[:,[7, 9, 10, 12, 13, 14, 15, 28, 31, 32]].to_numpy(), all_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1935, 610)"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "big_boi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.factorize(sentiment.EMOTION)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1935, 34)"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "sentiment.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6134020618556701\n0.5309278350515464\n0.5824742268041238\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "models = [\n",
    "           LogisticRegression(solver = 'lbfgs'),\n",
    "           ExtraTreesClassifier(),\n",
    "           NuSVC()\n",
    "        ]\n",
    "for m in models:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(big_boi, y, train_size=0.9)\n",
    "    m.fit(X_train, y_train)\n",
    "    pred = m.predict(X_test)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6030927835051546\n"
    }
   ],
   "source": [
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = [s.lower() for s in all_sents.iloc[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_artists = pd.read_csv(\"data/raw/SpotifyData.csv\")[[\"artist\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1764"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "idx = []\n",
    "idx_2 = []\n",
    "i = 0\n",
    "for j, our_artist in enumerate(our_artists):\n",
    "    # print(our_artist)\n",
    "    skip = 0\n",
    "    while i < len(artists) and editdistance.eval(str(our_artist[0]), artists[i]) > 4:\n",
    "        i = i + 1\n",
    "        if i >= len(artists):\n",
    "            i = j + 1\n",
    "            skip = 1\n",
    "            break\n",
    "        # print(str(our_artist[0]), artists[i])\n",
    "    if not skip:\n",
    "        idx += [i]\n",
    "        idx_2 += [j]\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['george michael', 'george michael'],\n       ['rob zombie', 'rob zombie'],\n       ['katatonia', 'katatonia'],\n       ...,\n       ['deine lakaien', 'deine lakaien'],\n       ['fatboy slim', 'fatboy slim'],\n       ['cooler kids', 'cooler kids']], dtype=object)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "np.hstack((np.array(artists)[idx].reshape(len(idx), 1), np.array(our_artists[:,0][idx_2].reshape(len(idx_2), 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1764, 610)"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "big_boi[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = pd.read_csv(\"data/preprocessed/spotify-data-preprocessed.csv\").to_numpy()[idx_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodality_is_here = np.hstack((audio[:,1:-4], big_boi[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1764, 623)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "multimodality_is_here.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6666666666666666\n"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(multimodality_is_here, y[idx], train_size=0.9)\n",
    "lg = ExtraTreesClassifier( n_estimators=1000)\n",
    "lg.fit(X_train, y_train)\n",
    "pred = lg.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accs = []\n",
    "confs = []\n",
    "\n",
    "# Training / Testing\n",
    "for train_index, test_index in skf.split(multimodality_is_here, y[idx]):\n",
    "    X_train, X_test = multimodality_is_here[train_index], multimodality_is_here[test_index]\n",
    "    y_train, y_test = y[idx][train_index ], y[idx][test_index]\n",
    "\n",
    "    model = ExtraTreesClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accs += [accuracy_score(y_test, y_pred)]\n",
    "    # confs += [confusion_matrix(y_test, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6621468926553671"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.703508602978942\n"
    }
   ],
   "source": [
    "fusion_audio = audio[:,1:-4]\n",
    "fusion_text = big_boi[idx]\n",
    "\n",
    "accs= []\n",
    "\n",
    "for train_index, test_index in skf.split(multimodality_is_here, y[idx]):\n",
    "    audio_train, audio_test = fusion_audio[train_index], fusion_audio[test_index]\n",
    "    text_train, text_test = fusion_text[train_index], fusion_text[test_index]\n",
    "    y_train, y_test = y[idx][train_index ], y[idx][test_index]\n",
    "\n",
    "    model1 = LogisticRegression()\n",
    "    model2 = LogisticRegression()\n",
    "    model1.fit(audio_train, y_train)\n",
    "    model2.fit(text_train, y_train)\n",
    "\n",
    "    model3 = LogisticRegression()\n",
    "    audio_predited = np.array(model1.predict_proba(audio_train))\n",
    "    text_predicted = np.array(model2.predict_proba(text_train))\n",
    "\n",
    "    fking = np.hstack((audio_predited, text_predicted))\n",
    "    model3.fit(fking, y_train)\n",
    "\n",
    "    abc1 = np.array(model1.predict_proba(audio_test))\n",
    "    abc2 = np.array(model2.predict_proba(text_test))\n",
    "    fking2 = np.hstack((abc1, abc2))\n",
    "    abc3 = model3.predict(fking2)\n",
    "\n",
    "    accs += [accuracy_score(y_test, abc3)]\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.7570621468926554,\n 0.6949152542372882,\n 0.655367231638418,\n 0.7175141242937854,\n 0.6988636363636364,\n 0.7102272727272727,\n 0.6477272727272727,\n 0.6704545454545454,\n 0.7215909090909091,\n 0.7613636363636364]"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit4539a5a599f24d04a1e10a4002ffd2cd",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}