{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading Lyrics...\nLoading Mood Targets...\n"
    }
   ],
   "source": [
    "# General imports\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Validation packages\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def get_lyrics():\n",
    "    print(\"Loading Lyrics...\")\n",
    "\n",
    "    pattern = re.compile(r\"\\[.*\\]|[oaOA]+h+|[\\?\\.\\,\\'\\!\\;\\:\\(\\)\\`]+\")\n",
    "    lyrics = []\n",
    "    files = os.listdir(\"data/lyrics/\")\n",
    "    idx = [int(f.split(\".\")[0]) for f in files]\n",
    "\n",
    "    for f in files:\n",
    "        with open(\"data/lyrics/\" + f, \"r\", encoding=\"utf-8\") as lines:\n",
    "            lyrics += [\" \".join([w for w in word_tokenize(re.sub(pattern, \"\", \" \".join(lines))) if not w in stop_words])]\n",
    "    return np.array(lyrics), idx\n",
    "\n",
    "def get_mood():\n",
    "    print(\"Loading Mood Targets...\")\n",
    "    d = pd.read_csv(\"data/preprocessed/spotify-data-preprocessed.csv\", \",\")\n",
    "    mood_vecs = [np.argmax(x) for x in d.iloc[:,-4:].to_numpy()]\n",
    "    return np.array(mood_vecs)\n",
    "\n",
    "\n",
    "X, idx = get_lyrics() ; y = get_mood()[idx]\n",
    "axis = np.sort(np.hstack((np.where(y==0), np.where(y==1))))\n",
    "X = X[axis,].reshape(axis.shape[1]) ; y = y[axis,].reshape(axis.shape[1])\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = 50\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "print(\"Loading Word Embeddings...\")\n",
    "with open(\"data/Twitter/glove.twitter.27B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy:  0.7415730337078652\nAccuracy:  0.7303370786516854\nAccuracy:  0.7344632768361582\nAccuracy:  0.7740112994350282\nAccuracy:  0.7457627118644068\nAverage accuracy:  0.7452294800990288\n"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "accs = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index ], y[test_index]\n",
    "\n",
    "    model = gensim.models.Word2Vec(X_train, size=50)\n",
    "\n",
    "    w2v = dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "\n",
    "    w2v_tfidf = Pipeline([\n",
    "        (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)),\n",
    "        # (\"extra trees\", LogisticRegression(solver = 'lbfgs'))])\n",
    "        # (\"extra trees\", RandomForestClassifier())])\n",
    "        (\"extra trees\", svm.NuSVC())])\n",
    "\n",
    "    w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_lr = w2v_tfidf.predict(X_test)\n",
    "\n",
    "    accs += [accuracy_score(y_test, y_pred_lr)]\n",
    "    print(\"Accuracy: \", accs[-1])\n",
    "print(\"Average accuracy: \", np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Scores\n",
    "\n",
    "## SVCs\n",
    "\n",
    "- 0.7125245984891766\n",
    "- ovo: 0.7023868469497873\n",
    "\n",
    "## NuSVC\n",
    "- 0.7441122325906177\n",
    "\n",
    "## RandomForest\n",
    "- 0.7396368945597664\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'support_vectors_'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-52597381e1ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m            linestyles=['--', '-', '--'])\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# plot support vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m ax.scatter(w2v_tfidf.support_vectors_[:, 0], w2v_tfidf.support_vectors_[:, 1], s=100,\n\u001b[0m\u001b[0;32m     15\u001b[0m            linewidth=1, facecolors='none', edgecolors='k')\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'support_vectors_'"
     ]
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = w2v_tfidf.decision_function(xy).reshape(XX.shape)\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "# plot support vectors\n",
    "ax.scatter(w2v_tfidf.support_vectors_[:, 0], w2v_tfidf.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def versiontuple(v):\n",
    "    return tuple(map(int, (v.split(\".\"))))\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-7c9a65660a15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-8c1061111869>\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[1;34m(X, y, classifier, test_idx, resolution)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# plot the decision surface\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mx1_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mx2_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "plot_decision_regions(X_test, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "markers = ('s', 'x', 'o', '-')\n",
    "colors = ('red', 'blue', 'lightgreen', 'yellow')\n",
    "cmap = ListedColormap(colors[:len(np.unique(y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<__main__.TfidfEmbeddingVectorizer at 0x26553dd92e0>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit4539a5a599f24d04a1e10a4002ffd2cd",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}